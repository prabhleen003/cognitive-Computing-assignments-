{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b68612c-fbca-436c-8b85-b347f8a2d498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97381ce0-8797-4244-8a00-d9e335547c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Technology has drastically changed the way we live, work, and communicate. \n",
    "From the internet to smartphones, technology is constantly evolving and shaping our daily lives. \n",
    "The future of technology holds immense potential with advancements in AI, robotics, and quantum computing. \n",
    "We are only scratching the surface of what technology can achieve.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b0c3464-8031-49d2-81a0-eba19018b515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1.1: Convert text to lowercase and remove punctuation\n",
    "text_lower = text.lower()\n",
    "text_clean = text_lower.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9555fbb3-b33c-4046-a726-613bece8e39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Q1.2: Tokenize the text into words and sentences\n",
    "words = word_tokenize(text_clean)\n",
    "sentences = sent_tokenize(text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6006599-5a62-4886-8ac8-1b9de3bd2d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\prabh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# Q1.3: Remove stopwords using NLTK's stopwords list\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_words = [word for word in words if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "155b617c-e523-4acc-8917-65dfc82c4c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1.4 - Word Frequency Distribution: Counter({'technology': 4, 'drastically': 1, 'changed': 1, 'way': 1, 'live': 1, 'work': 1, 'communicate': 1, 'internet': 1, 'smartphones': 1, 'constantly': 1, 'evolving': 1, 'shaping': 1, 'daily': 1, 'lives': 1, 'future': 1, 'holds': 1, 'immense': 1, 'potential': 1, 'advancements': 1, 'ai': 1, 'robotics': 1, 'quantum': 1, 'computing': 1, 'scratching': 1, 'surface': 1, 'achieve': 1})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Q1.4: Word frequency distribution (excluding stopwords)\n",
    "word_freq = Counter(filtered_words)\n",
    "print(\"Q1.4 - Word Frequency Distribution:\", word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daef38da-bbdb-4782-a384-c1779e695ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45679ac5-1ed0-4ecc-ab0b-1e1b2b69249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2.1: Take tokenized words after stopword removal\n",
    "# (filtered_words already done in Q1)\n",
    "\n",
    "# Q2.2: Apply stemming using NLTK's PorterStemmer and LancasterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "\n",
    "porter_stemmed = [porter_stemmer.stem(word) for word in filtered_words]\n",
    "lancaster_stemmed = [lancaster_stemmer.stem(word) for word in filtered_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "883de498-dac2-4cb2-a042-391e849a87bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2.2: Apply stemming using NLTK's PorterStemmer and LancasterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "\n",
    "porter_stemmed = [porter_stemmer.stem(word) for word in filtered_words]\n",
    "lancaster_stemmed = [lancaster_stemmer.stem(word) for word in filtered_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ae71430-18f1-47a7-be93-f12d9a3a5077",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\prabh\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "# Q2.3: Apply lemmatization using NLTK's WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f90fe88b-f642-41f9-a013-87e2c2b9eb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2.4 - Original Words: ['technology', 'drastically', 'changed', 'way', 'live', 'work', 'communicate', 'internet', 'smartphones', 'technology']\n",
      "Q2.4 - Porter Stemmed: ['technolog', 'drastic', 'chang', 'way', 'live', 'work', 'commun', 'internet', 'smartphon', 'technolog']\n",
      "Q2.4 - Lancaster Stemmed: ['technolog', 'drast', 'chang', 'way', 'liv', 'work', 'commun', 'internet', 'smartphon', 'technolog']\n",
      "Q2.4 - Lemmatized Words: ['technology', 'drastically', 'changed', 'way', 'live', 'work', 'communicate', 'internet', 'smartphones', 'technology']\n"
     ]
    }
   ],
   "source": [
    "# Q2.4: Compare and display results\n",
    "print(\"Q2.4 - Original Words:\", filtered_words[:10])\n",
    "print(\"Q2.4 - Porter Stemmed:\", porter_stemmed[:10])\n",
    "print(\"Q2.4 - Lancaster Stemmed:\", lancaster_stemmed[:10])\n",
    "print(\"Q2.4 - Lemmatized Words:\", lemmatized_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9719f391-d43e-49a3-9d97-d49cd62ef714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3.2a - Words longer than 5 letters: ['technology', 'drastically', 'changed', 'communicate', 'internet', 'smartphones', 'technology', 'constantly', 'evolving', 'shaping', 'future', 'technology', 'immense', 'potential', 'advancements', 'robotics', 'quantum', 'computing', 'scratching', 'surface', 'technology', 'achieve']\n",
      "Q3.2b - Numbers: []\n",
      "Q3.2c - Capitalized words: []\n",
      "Q3.3a - Words with only alphabets: ['technology', 'has', 'drastically', 'changed', 'the', 'way', 'we', 'live', 'work', 'and', 'communicate', 'from', 'the', 'internet', 'to', 'smartphones', 'technology', 'is', 'constantly', 'evolving', 'and', 'shaping', 'our', 'daily', 'lives', 'the', 'future', 'of', 'technology', 'holds', 'immense', 'potential', 'with', 'advancements', 'in', 'ai', 'robotics', 'and', 'quantum', 'computing', 'we', 'are', 'only', 'scratching', 'the', 'surface', 'of', 'what', 'technology', 'can', 'achieve']\n",
      "Q3.3b - Words starting with a vowel: ['and', 'internet', 'is', 'evolving', 'and', 'our', 'of', 'immense', 'advancements', 'in', 'ai', 'and', 'are', 'only', 'of', 'achieve']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Q3.1: Original text from Q1 (text_clean)\n",
    "# (Using text_clean from Q1)\n",
    "\n",
    "# Q3.2a: Extract words with more than 5 letters\n",
    "words_longer_than_5 = re.findall(r'\\b\\w{6,}\\b', text_clean)\n",
    "\n",
    "# Q3.2b: Extract all numbers (if any exist)\n",
    "numbers = re.findall(r'\\b\\d+\\b', text_clean)\n",
    "\n",
    "# Q3.2c: Extract all capitalized words\n",
    "capitalized_words = re.findall(r'\\b[A-Z][a-z]*\\b', text_clean)\n",
    "\n",
    "# Q3.3a: Split text into words containing only alphabets (remove digits and special characters)\n",
    "words_only_alpha = re.findall(r'\\b[a-zA-Z]+\\b', text_clean)\n",
    "\n",
    "# Q3.3b: Extract words starting with a vowel\n",
    "words_starting_with_vowel = re.findall(r'\\b[aeiouAEIOU]\\w*', text_clean)\n",
    "\n",
    "# Display the results\n",
    "print(\"Q3.2a - Words longer than 5 letters:\", words_longer_than_5)\n",
    "print(\"Q3.2b - Numbers:\", numbers)\n",
    "print(\"Q3.2c - Capitalized words:\", capitalized_words)\n",
    "print(\"Q3.3a - Words with only alphabets:\", words_only_alpha)\n",
    "print(\"Q3.3b - Words starting with a vowel:\", words_starting_with_vowel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2abf874-eac9-4302-998c-05dacdd94b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4.1: Original text from Q1\n",
    "# (Using text from Q1)\n",
    "\n",
    "# Q4.2: Custom Tokenization Function\n",
    "def custom_tokenizer(text):\n",
    "    text = re.sub(r\"([a-zA-Z])'([a-zA-Z])\", r\"\\1'\\2\", text)  # Keeps contractions\n",
    "    text = re.sub(r\"\\b[\\w'-]+(?:-\\w+)*\\b\", r\" \\g<0> \", text)  # Keeps hyphenated words as single tokens\n",
    "    text = re.sub(r'\\d+\\.\\d+', r'NUMBER', text)  # Keeps decimal numbers intact\n",
    "    text_clean = re.sub(r'[^a-zA-Z0-9\\'- ]', ' ', text)  # Remove other punctuation\n",
    "    return text_clean.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e2fc67-4458-4954-a7db-5e712570881b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4.3: Regex Substitutions - using the random URL from the text\n",
    "def regex_substitutions(text):\n",
    "   \n",
    "    text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b', '<EMAIL>', text)  \n",
    "   \n",
    "    text = re.sub(r'https?://\\S+', '<URL>', text)  \n",
    "    # Replace phone numbers (formats: 123-456-7890 or +91 9876543210)\n",
    "    text = re.sub(r'\\+?\\d{1,3}\\s?\\(?\\d{1,4}\\)?\\s?\\d{1,4}[-.\\s]?\\d{1,4}[-.\\s]?\\d{1,4}', '<PHONE>', text)  \n",
    "    return text\n",
    "\n",
    "# Use the functions to process the text\n",
    "custom_tokens = custom_tokenizer(text)\n",
    "cleaned_text = regex_substitutions(text)\n",
    "\n",
    "# Display the results\n",
    "print(\"Q4.2 - Custom Tokenized Text:\", custom_tokens[:10])  # First 10 tokens for brevity\n",
    "print(\"Q4.3 - Cleaned Text:\", cleaned_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
